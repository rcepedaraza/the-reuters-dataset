{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78d3351",
   "metadata": {},
   "source": [
    "## The Reutres dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b627f1ab",
   "metadata": {},
   "source": [
    "A set of short newswires and their topics, published by Reuters in 1986. There are 46 different topics and each topic has at least 10 examples in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd33140",
   "metadata": {},
   "source": [
    "### Loading the Reuters dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008a0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.utils import to_categorical # Converts a class vector (integers) to binary class matrix.\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c9c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/ricardo/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Restrict the data to the 10,000 most frequently occurring words found in the data.\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e802ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:\n",
      "(8982,)\n",
      "(8982,)\n",
      "\n",
      "Test shape:\n",
      "(2246,)\n",
      "(2246,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\")\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(\"\\nTest shape:\")\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50edf8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0]) # word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07bc114a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0]) # Topic index (integer between 0 and 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3c1db",
   "metadata": {},
   "source": [
    "### Decoding newswires back to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c686eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]]) # offset by 3 cause reserved indices\n",
    "print(decoded_newswire)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d6016",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58803ac",
   "metadata": {},
   "source": [
    "#### Encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc3eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_seq(sequences, dim=10000):\n",
    "    results = np.zeros((len(sequences), dim))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5d43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_seq(train_data) # Vectorized train data\n",
    "x_test = vectorize_seq(test_data) # Vectorized test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db57e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To vectorize the labels\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd90826",
   "metadata": {},
   "source": [
    "### Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd795bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# For each input sample, the network will output a 46-dimensional vector.\n",
    "model.add(layers.Dense(46, activation='softmax')) # Softmax converts a real vector to a vector of categorical probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002aee3c",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38fd7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6290d9a",
   "metadata": {},
   "source": [
    "### Validating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab4285",
   "metadata": {},
   "source": [
    "#### Setting aside a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef6f89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ecdfb",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 20 epochs\n",
    "EPOCHS = 20\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
